{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-dbf304ec0615>:95: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From c:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-1-dbf304ec0615>:106: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "epoch 0, training accuracy: 0.2150, loss: 2.21745, time: 2.2070748805999756\n",
      "Model saved in file: checkpoint\\model.ckpt\n",
      "epoch 20, training accuracy: 0.9250, loss: 0.81390, time: 20.758396863937378\n",
      "epoch 40, training accuracy: 0.9150, loss: 0.73065, time: 19.472097635269165\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dbf304ec0615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m# 开始反向传播算法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n\u001b[1;32m--> 166\u001b[1;33m                                            is_training: True})\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[1;31m# 计算损失和精度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jabes\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#导入相关的库\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import time\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#这里用slim这个API来进行卷积网络构建\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "#定义卷积神经网络模型\n",
    "#网络架构是卷积网络--最大池化--卷积网络--最大池化---flatten---MLP-softmax的全连接MLP\n",
    "def model(inputs, is_training, dropout_rate, num_classes, scope='Net'):\n",
    "    inputs = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "    with tf.variable_scope(scope):\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                            normalizer_fn=slim.batch_norm):\n",
    "            net = slim.conv2d(inputs, 32, [5, 5], padding='SAME', scope='conv1')\n",
    "            net = slim.max_pool2d(net, 2, stride=2, scope='maxpool1')\n",
    "            tf.summary.histogram(\"conv1\", net)\n",
    "\n",
    "            net = slim.conv2d(net, 64, [5, 5], padding='SAME', scope='conv2')\n",
    "            net = slim.max_pool2d(net, 2, stride=2, scope='maxpool2')\n",
    "            tf.summary.histogram(\"conv2\", net)\n",
    "\n",
    "            net = slim.flatten(net, scope='flatten')\n",
    "            fc1 = slim.fully_connected(net, 1024, scope='fc1')\n",
    "            tf.summary.histogram(\"fc1\", fc1)\n",
    "\n",
    "            net = slim.dropout(fc1, dropout_rate, is_training=is_training, scope='fc1-dropout')\n",
    "            net = slim.fully_connected(net, num_classes, scope='fc2')\n",
    "\n",
    "            return net, fc1\n",
    "\n",
    "\n",
    "def create_sprite_image(images):\n",
    "    \"\"\"更改图片的shape\"\"\"\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "\n",
    "    sprite_image = np.ones((img_h * n_plots, img_w * n_plots))\n",
    "\n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                sprite_image[i * img_h:(i + 1) * img_h,\n",
    "                j * img_w:(j + 1) * img_w] = this_img\n",
    "\n",
    "    return sprite_image\n",
    "\n",
    "\n",
    "def vector_to_matrix_mnist(mnist_digits):\n",
    "    \"\"\"把正常的mnist数字图片(batch,28*28)这个格式，转换为新的张量形状(batch,28,28)\"\"\"\n",
    "    return np.reshape(mnist_digits, (-1, 28, 28))\n",
    "\n",
    "\n",
    "def invert_grayscale(mnist_digits):\n",
    "    \"\"\"处理下图片颜色，黑色变白，白色边黑\"\"\"\n",
    "    return 1 - mnist_digits\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义参数\n",
    "    #学习率\n",
    "    learning_rate = 1e-4\n",
    "    #定义迭代参数\n",
    "    total_epoch = 500\n",
    "    #定义批量\n",
    "    batch_size = 200\n",
    "    #程序运行中打印频率\n",
    "    display_step = 20\n",
    "    #程序运行中保存结果的频率\n",
    "    save_step = 100\n",
    "    load_checkpoint = False\n",
    "    checkpoint_dir = \"checkpoint\"\n",
    "    checkpoint_name = 'model.ckpt'\n",
    "    #结果存放的路径\n",
    "    logs_path = \"logs\"\n",
    "    #定义我们使用多少个图片\n",
    "    test_size = 1000\n",
    "    #定义第二层路径\n",
    "    projector_path = 'projector'\n",
    "\n",
    "    # 网络参数\n",
    "    n_input = 28 * 28   # 每个图片是28*28个像素，也就是784个特征\n",
    "    n_classes = 10  # MNIST数据集有0-9是个类别的结果\n",
    "    dropout_rate = 0.5  # Dropout的比率\n",
    "\n",
    "    mnist = input_data.read_data_sets('MNIST-data', one_hot=True)\n",
    "\n",
    "    # 定义计算图\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name='InputData')\n",
    "    y = tf.placeholder(tf.float32, [None, n_classes], name='LabelData')\n",
    "    is_training = tf.placeholder(tf.bool, name='IsTraining')\n",
    "    keep_prob = dropout_rate\n",
    "\n",
    "    logits, fc1 = model(x, is_training, keep_prob, n_classes)\n",
    "\n",
    "    with tf.name_scope('Loss'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "    projector_dir = os.path.join(logs_path, projector_path)\n",
    "    path_metadata = os.path.join(projector_dir,'metadata.tsv')\n",
    "    path_sprites = os.path.join(projector_dir, 'mnistdigits.png')\n",
    "    # 检查结果目录的状态\n",
    "    if not os.path.exists(projector_dir):\n",
    "        os.makedirs(projector_dir)\n",
    "\n",
    "    # 这里进行嵌入\n",
    "    mnist_test = input_data.read_data_sets('MNIST-data', one_hot=False)\n",
    "    batch_x_test = mnist_test.test.images[:test_size]\n",
    "    batch_y_test = mnist_test.test.labels[:test_size]\n",
    "\n",
    "    embedding_var = tf.Variable(tf.zeros([test_size, 1024]), name='embedding')\n",
    "    assignment = embedding_var.assign(fc1)\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "    embedding.metadata_path = os.path.join(projector_path,'metadata.tsv')\n",
    "    embedding.sprite.image_path = os.path.join(projector_path, 'mnistdigits.png')\n",
    "    embedding.sprite.single_image_dim.extend([28,28])\n",
    "\n",
    "    # 初始化变量\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # 'Saver' op to save and restore all the variables\n",
    "    saver = tf.train.Saver()\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # 运行计算图\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Restore model weights from previously saved model\n",
    "        prev_model = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if load_checkpoint:\n",
    "            if prev_model:\n",
    "                saver.restore(sess, prev_model.model_checkpoint_path)\n",
    "                print('Checkpoint found, {}'.format(prev_model))\n",
    "            else:\n",
    "                print('No checkpoint found')\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "        projector.visualize_embeddings(summary_writer, config)\n",
    "        start_time = time.time()\n",
    "        # 开始训练\n",
    "        for epoch in range(total_epoch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # reshapeX = np.reshape(batch_x, [-1, 28, 28, 1])\n",
    "            # 开始反向传播算法\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                           is_training: True})\n",
    "            if epoch % display_step == 0:\n",
    "                # 计算损失和精度\n",
    "                cost, acc, summary = sess.run([loss, accuracy, merged_summary_op],\n",
    "                                              feed_dict={x: batch_x,\n",
    "                                                         y: batch_y,\n",
    "                                                         is_training: False})\n",
    "                elapsed_time = time.time() - start_time\n",
    "                start_time = time.time()\n",
    "                print('epoch {}, training accuracy: {:.4f}, loss: {:.5f}, time: {}'\n",
    "                      .format(epoch, acc, cost, elapsed_time))\n",
    "                summary_writer.add_summary(summary, epoch)\n",
    "            if epoch % save_step == 0:\n",
    "                # 保存训练的结果\n",
    "                sess.run(assignment, feed_dict={x: mnist.test.images[:test_size],\n",
    "                                                y: mnist.test.labels[:test_size], is_training: False})\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "                save_path = saver.save(sess, checkpoint_path)\n",
    "                print(\"Model saved in file: {}\".format(save_path))\n",
    "\n",
    "        # 保存结果\n",
    "        saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), 1)\n",
    "        # 创建可视化的图片\n",
    "        to_visualise = batch_x_test\n",
    "        to_visualise = vector_to_matrix_mnist(to_visualise)\n",
    "        to_visualise = invert_grayscale(to_visualise)\n",
    "        sprite_image = create_sprite_image(to_visualise)\n",
    "        # 保存可视化的图片\n",
    "        plt.imsave(path_sprites, sprite_image, cmap='gray')\n",
    "        # 写文件\n",
    "        with open(path_metadata, 'w') as f:\n",
    "            f.write(\"Index\\tLabel\\n\")\n",
    "            for index, label in enumerate(batch_y_test):\n",
    "                f.write(\"%d\\t%d\\n\" % (index, label))\n",
    "\n",
    "        print(\"训练完成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
